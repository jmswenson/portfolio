{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For a set of csv files, read them in one at a time, perform t-SNE followed by DBSCAN, save figures and results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn import decomposition, metrics\n",
    "from sklearn.preprocessing import scale, robust_scale\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in/Users/tswenson/Documents/Joels/Health_Data_Science/COMPANY_consulting_project/datasets/screen_357_cell_plate_1_labeled_merged_csvs/LABELLED_by_cell_type_screen_357_cell_plate_1_labeled_merged_screen_357_cell_plate_1_labeled_merged_well_n22.csv\n",
      "Starting t-SNE calculation using this many data points: 12680\n",
      "Done with t-SNE calculation\n",
      "Starting DBSCAN\n",
      "Plotting DBSCAN with eps = to 0.520504731861\n",
      "[[-1, 46, 2], [0, 98, 3], [1, 11086, 7], [2, 10, 0], [3, 347, 0], [4, 20, 0], [5, 15, 0], [6, 11, 0], [7, 85, 0], [8, 209, 0], [9, 43, 0], [10, 335, 0], [11, 206, 0], [12, 20, 0], [13, 117, 0], [14, 10, 0], [15, 10, 0]]\n",
      "Plotting grouped barplots\n",
      "Done with /Users/tswenson/Documents/Joels/Health_Data_Science/COMPANY_consulting_project/datasets/screen_357_cell_plate_1_labeled_merged_csvs/LABELLED_by_cell_type_screen_357_cell_plate_1_labeled_merged_screen_357_cell_plate_1_labeled_merged_well_n22.csv\n"
     ]
    }
   ],
   "source": [
    "#directory = '/Users/tswenson/Documents/Joels/Health_Data_Science/COMPANY_consulting_project/datasets/merged_csvs/'\n",
    "directory = '/Users/tswenson/Documents/Joels/Health_Data_Science/COMPANY_consulting_project/datasets/screen_357_cell_plate_1_labeled_merged_csvs/'\n",
    "df = []\n",
    "do_boxplots = 0; # binary, 1 indicates that boxplots should be made\n",
    "#for filename in glob.glob(directory + \"LABELLED*.csv\"): # reads through all files in this directory looking for *.csv and ignores sub-directories\n",
    "for filename in glob.glob(directory + \"LABELLED*n22*.csv\"): # reads through all files in this directory looking for *.csv and ignores sub-directories\n",
    "    print(\"Read in\" + filename)\n",
    "    # Set some variables equal to \"None\" so that I don't have surprises later\n",
    "    my_data=None; my_data_headers=None; meta_headers=None; my_data_data_headers=None\n",
    "    my_scaled_data = None; word_as_num = None; tsne_out_mink = None; labels = None\n",
    "    \n",
    "    my_data=pd.read_csv(filename, index_col=0)\n",
    "    my_data_headers = list(my_data)\n",
    "    meta_headers = [\"Width\",\"cell_label\",\"cell_plate\",\"lineage\",\"screen\",\"well\",\"Time\"]\n",
    "    my_data_data_headers = [x for x in my_data_headers if not x in meta_headers]\n",
    "    # Scale the data columns\n",
    "    my_scaled_data = scale(my_data[my_data_data_headers])\n",
    "    # Make a list where cell_label is converted to numbers for plotting\n",
    "    word_as_num=[]\n",
    "    for word in my_data['cell_label']:\n",
    "        if word == \"unlabelled\":\n",
    "            word_as_num.append(\"0\")\n",
    "        if word == \"blast\":\n",
    "            word_as_num.append(\"0.5\")\n",
    "    lr = 3000 # Set the learning rate for t-SNE\n",
    "    # Perform t-SNE\n",
    "    print(\"Starting t-SNE calculation using this many data points: \" + str(my_scaled_data.shape[0]))\n",
    "    tsne_out_mink = TSNE(metric='minkowski', learning_rate=lr, n_iter=lr, random_state=11).fit_transform(my_scaled_data)\n",
    "    print(\"Done with t-SNE calculation\")\n",
    "    # Plot and save the output\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.gcf().clear()\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(tsne_out_mink[:, 0], tsne_out_mink[:, 1], c= word_as_num, cmap=plt.cm.viridis)\n",
    "    plt.savefig(filename + \"__tsne.png\")\n",
    "    plt.close()\n",
    "    # Do DBSCAN on the tSNEd data\n",
    "    print(\"Starting DBSCAN\")\n",
    "    # Set DBSCAN eps hyper-parameter automatically\n",
    "    eps_ = float(0.6)*float(11000)/float(my_scaled_data.shape[0])\n",
    "    dbsc = DBSCAN(eps = eps_, min_samples=10).fit(tsne_out_mink)\n",
    "    labels = dbsc.labels_\n",
    "    core_samples = np.zeros_like(labels, dtype = bool)\n",
    "    core_samples[dbsc.core_sample_indices_] = True\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(\"Plotting DBSCAN with eps = to \" + str(eps_))\n",
    "    # Plot the DBSCAN results\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.gcf().clear()\n",
    "    plt.subplot(121)\n",
    "    col = np.linspace(0,1,len(unique_labels))\n",
    "    for i in xrange(len(unique_labels)):\n",
    "        plt.plot(tsne_out_mink[np.where(labels==unique_labels[i])[0], 0], \n",
    "             tsne_out_mink[np.where(labels==unique_labels[i])[0], 1],\n",
    "                #'o', mfc=plt.cm.viridis(col[i]), label=unique_labels[i])\n",
    "                'o', mfc=plt.cm.nipy_spectral(col[i]), label=unique_labels[i])\n",
    "                #'o', mfc=plt.cm.prism(col[i]), label=unique_labels[i])\n",
    "                #'o', mfc=plt.cm.flag(col[i]), label=unique_labels[i])\n",
    "    plt.legend(loc='best', frameon=False)\n",
    "    plt.savefig(filename + \"__DBSCAN_eps\" + str(eps_) +\"_of_tsne.png\")\n",
    "    plt.close()\n",
    "    # Summarize the combination of tSNE and DBSCAN results\n",
    "    tsne_db = [] # This will be a list of lists where the 1st entry is the cluster ID, 2nd: is\n",
    "    ## how many \"unlabelled\" are in that cluster, 3rd: number of blast, 4th: number of healthy.\n",
    "    for i in xrange(len(unique_labels)):\n",
    "        clst_index = my_data['cell_label'][np.where(labels==unique_labels[i])[0]]\n",
    "        if clst_index.empty == True:\n",
    "            print(\"Cluster index and original data don't line up right. STOP AND FIX\")\n",
    "            break\n",
    "        tsne_db.append([unique_labels[i],sum(clst_index=='unlabelled'),\n",
    "                         sum(clst_index=='blast')])\n",
    "    print(tsne_db)\n",
    "    # Prepare to plot the results as grouped barplots\n",
    "    print(\"Plotting grouped barplots\")\n",
    "    tsne_db_df = pd.DataFrame(tsne_db,columns=[\"Cluster Label\",\"Unlabelled\",\"Blast\"])\n",
    "    tsne_db_df_melted = pd.melt(tsne_db_df,value_vars=[\"Unlabelled\",\"Blast\"],id_vars=\"Cluster Label\")\n",
    "    plt.gcf().clear()\n",
    "    ax = sns.barplot(hue=\"variable\",y=\"value\",x=\"Cluster Label\",data=tsne_db_df_melted,log='y')\n",
    "    plt.savefig(filename + '__barplot.png')\n",
    "    plt.close()\n",
    "    if do_boxplots == 1:\n",
    "        # For each cluster plot boxplots of each feature\n",
    "        print(\"Starting boxplots plotting\")\n",
    "        for i in xrange(len(unique_labels)):\n",
    "            clst_index = my_data.ix[np.where(labels==unique_labels[i])[0],my_data_data_headers]\n",
    "            clst_index_scaled = my_scaled_data[np.where(labels==unique_labels[i])[0],]\n",
    "            # Plot the unscaled data\n",
    "            locations = range(1,(len(my_data_data_headers)+1))\n",
    "            plt.figure()\n",
    "            plt.gcf().clear()\n",
    "            plt.boxplot(clst_index.as_matrix(),positions=locations)\n",
    "            plt.title(\"Cluster number \" + str(unique_labels[i]))\n",
    "            plt.ylabel('A.U.')\n",
    "            plt.xticks(locations, my_data_data_headers,rotation='vertical')\n",
    "            #plt.yscale('log')\n",
    "            percs = (clst_index.describe(percentiles=[0.1,0.5,0.9]))\n",
    "            plt.ylim(percs.iloc[4].min(),percs.iloc[6].max())\n",
    "            #plt.show()\n",
    "            plt.savefig(filename + \"__boxplots_of_cluster\" +str(unique_labels[i])+\".png\")\n",
    "            plt.close()\n",
    "            locations = range(1,(len(my_data_data_headers)+1))\n",
    "            # Plot the scaled data\n",
    "            plt.figure()\n",
    "            plt.gcf().clear()\n",
    "            plt.boxplot(clst_index_scaled,positions=locations)\n",
    "            plt.title(\"Cluster number \" + str(unique_labels[i]))\n",
    "            plt.ylabel('A.U.')\n",
    "            plt.xticks(locations, my_data_data_headers,rotation='vertical')\n",
    "            #plt.yscale('log')\n",
    "            percs_scaled = pd.DataFrame(clst_index_scaled).describe(percentiles=[0.1,0.5,0.9])\n",
    "            plt.ylim(percs_scaled.iloc[4].min(),percs_scaled.iloc[6].max())\n",
    "            plt.savefig(filename + \"__scaled_boxplots_of_cluster\" + str(unique_labels[i]) + \".png\")\n",
    "            plt.close()\n",
    "    print(\"Done with \" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the following code to the above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### I started to work on this, but didn't finish. Psuedo code is mostly done.\n",
    "'''\n",
    "#### Export the labelled populations of a well\n",
    "# Find the fcs file that matches the csv file. \n",
    "## First get rid of the .csv, then get rid of the path and the LABELLED,\n",
    "## now add the path back to the core name identified above, check that \n",
    "## it only matches one file, print matches for user to verify\n",
    "output_name = filename.split(\".csv\")[0]\n",
    "filename_fcs = \n",
    "for i in xrange(len(unique_labels)):\n",
    "    fcs_file = FCSParser(path)\n",
    "    #cluster_data = my_data_keepers.iloc[np.where(labels==unique_labels[i])[0]].astype('float')\n",
    "    #new_fcs_file = fcs_file.clone(data=cluster_data.as_matrix().astype('float'))\n",
    "    new_fcs_file = fcs_file.clone(data= fcs_file.data[np.where(labels==unique_labels[i])[0]].astype('float'))\n",
    "    new_fcs_file.annotation['cluster_label'] = unique_labels[i]\n",
    "    #new_fcs_file.write_to_file(\"/Users/tswenson/Documents/Joels/TEST.fcs\")\n",
    "    new_fcs_file.write_to_file(output_name + '__cluster_' + str(unique_labels[i])\\\n",
    "                               + '_exported_'\\\n",
    "                               + datetime.datetime.now().strftime('%Y.%m.%d %I.%M.%S')\\\n",
    "                               + '.fcs')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Export Well C3 or my_data\n",
    "path = '/Users/tswenson/Documents/Joels/Health_Data_Science/COMPANY_consulting_project/datasets/training_set/screen_357_cell_plate_1_well_C3_original.fcs'\n",
    "output_name = path.split(\".fcs\")[0]\n",
    "for i in xrange(len(unique_labels)):\n",
    "    fcs_file = FCSParser(path)\n",
    "    #cluster_data = my_data_keepers.iloc[np.where(labels==unique_labels[i])[0]].astype('float')\n",
    "    #new_fcs_file = fcs_file.clone(data=cluster_data.as_matrix().astype('float'))\n",
    "    new_fcs_file = fcs_file.clone(data= fcs_file.data[np.where(labels==unique_labels[i])[0]].astype('float'))\n",
    "    new_fcs_file.annotation['cluster_label'] = unique_labels[i]\n",
    "    #new_fcs_file.write_to_file(\"/Users/tswenson/Documents/Joels/TEST.fcs\")\n",
    "    new_fcs_file.write_to_file(output_name + '__cluster_' + str(unique_labels[i])\\\n",
    "                               + '_exported_'\\\n",
    "                               + datetime.datetime.now().strftime('%Y.%m.%d %I.%M.%S')\\\n",
    "                               + '.fcs')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "### Only plot clusters with more than 50 events\n",
    "tsne_db_df_50 = tsne_db_df[tsne_db_df.sum(axis=1)>110]\n",
    "print(len(tsne_db_df_50))\n",
    "tsne_db_df_50_melted = pd.melt(tsne_db_df_50,value_vars=[\"Unlabelled\",\"Blast\"],id_vars=\"Cluster Label\")\n",
    "ax = sns.barplot(hue=\"variable\",y=\"value\",x=\"Cluster Label\",data=tsne_db_df_50_melted,log='y')\n",
    "plt.savefig('e21_largeR_clstrs_only__barplot.png')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py2-env]",
   "language": "python",
   "name": "Python [py2-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
